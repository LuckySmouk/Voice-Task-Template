import os
import sys
import logging
import vosk
import time
import pyaudio
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SpeechRecognition")

# –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ Vosk
MODEL_PATH = os.path.join("models", "ru", "vosk-model-small-ru-0.22")

def check_model():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ Vosk"""
    if not os.path.exists(MODEL_PATH):
        logger.error(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {MODEL_PATH}")
        print(f"‚ùå –ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {MODEL_PATH}")
        print("–°–∫–∞—á–∞–π—Ç–µ —Å https://alphacephei.com/vosk/models")
        print("–∏ —Ä–∞—Å–ø–∞–∫—É–π—Ç–µ –≤ –ø–∞–ø–∫—É models/ru")
        return False
    return True

def listen_command():
    """–†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ä–µ—á—å –ª–æ–∫–∞–ª—å–Ω–æ —á–µ—Ä–µ–∑ Vosk"""
    try:
        if not check_model():
            return None
            
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–æ–¥–∏–Ω —Ä–∞–∑)
        if not hasattr(listen_command, 'model'):
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Vosk –∏–∑ {MODEL_PATH}")
            listen_command.model = vosk.Model(MODEL_PATH)
        
        recognizer = vosk.KaldiRecognizer(listen_command.model, 16000)
        
        p = pyaudio.PyAudio()
        
        # –ü–æ–∏—Å–∫ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –≤–≤–æ–¥–∞
        device_index = None
        for i in range(p.get_device_count()):
            dev_info = p.get_device_info_by_index(i)
            if int(dev_info.get('maxInputChannels', 0)) > 0:
                device_index = i
                break
        
        if device_index is None:
            logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–≤–æ–¥–∞")
            return None
        
        frames_per_buffer = 4096
        stream = p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=16000,
            input=True,
            frames_per_buffer=frames_per_buffer,
            input_device_index=device_index
        )
        
        print("üé§ –ì–æ–≤–æ—Ä–∏—Ç–µ...")
        timeout = 35  # —Å–µ–∫—É–Ω–¥
        start_time = time.time()
        
        while True:
            try:
                data = stream.read(frames_per_buffer, exception_on_overflow=False)
                
                if recognizer.AcceptWaveform(data):
                    result = json.loads(recognizer.Result())
                    recognized_text = result.get("text", "")
                    if recognized_text:
                        stream.stop_stream()
                        stream.close()
                        p.terminate()
                        return recognized_text
                else:
                    partial = json.loads(recognizer.PartialResult())
                    if "partial" in partial and partial["partial"]:
                        print(f"–°–ª—É—à–∞—é: {partial['partial']}", end='\r')
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞
                if time.time() - start_time > timeout:
                    print("\n‚è∞ –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è —Ä–µ—á–∏")
                    break
                    
            except OSError as e:
                if "Input overflowed" in str(e):
                    logger.warning("–ü–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –±—É—Ñ–µ—Ä–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞")
                    continue
                else:
                    raise
        
        stream.stop_stream()
        stream.close()
        p.terminate()
        return None
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: {e}", exc_info=True)
        return None
